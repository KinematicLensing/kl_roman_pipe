"""
Parameter recovery tests using likelihood slicing.

Tests validate that:
1. Forward models are implemented correctly
2. Likelihood functions are well-behaved
3. True parameters can be recovered in principle

Each test generates synthetic data with known parameters, then slices the
log-likelihood along each parameter dimension to verify it peaks near the
true value.

Diagnostic plots are generated by default showing:
- 2x3 panel plots: [noisy|true|noisy-true] and [noisy|model|noisy-model]
- Likelihood slices for each parameter with true value and recovered peak
"""

import pytest
import jax.numpy as jnp
import numpy as np
from typing import Dict, Tuple

from kl_pipe.parameters import ImagePars
from kl_pipe.velocity import CenteredVelocityModel, OffsetVelocityModel
from kl_pipe.intensity import InclinedExponentialModel
from kl_pipe.model import KLModel
from kl_pipe.synthetic import SyntheticVelocity, SyntheticIntensity
from kl_pipe.likelihood import (
    create_jitted_likelihood_velocity,
    create_jitted_likelihood_intensity,
    create_jitted_likelihood_joint,
)
from kl_pipe.utils import build_map_grid_from_image_pars, get_test_dir

# Import our shared test utilities
from test_utils import (
    TestConfig,
    slice_all_parameters,
    plot_likelihood_slices,
    assert_parameter_recovery,
)
from kl_pipe.diagnostics import plot_data_comparison_panels


# ==============================================================================
# Pytest Fixtures
# ==============================================================================


@pytest.fixture(scope="module")
def test_config():
    """
    Test configuration fixture.

    This replaces global variables and makes configuration explicit.
    To modify behavior, edit TestConfig in test_utils.py.
    """

    out_dir = get_test_dir() / "out" / "likelihood_slices"
    config = TestConfig(out_dir, include_poisson_noise=False)
    config.output_dir.mkdir(parents=True, exist_ok=True)

    return config


@pytest.fixture
def velocity_grids(test_config):
    """Pre-computed coordinate grids for velocity tests (32x32)."""
    X, Y = build_map_grid_from_image_pars(
        test_config.image_pars_velocity, unit='arcsec', centered=True
    )
    return X, Y


@pytest.fixture
def intensity_grids(test_config):
    """Pre-computed coordinate grids for intensity tests (64x64)."""
    X, Y = build_map_grid_from_image_pars(
        test_config.image_pars_intensity, unit='arcsec', centered=True
    )
    return X, Y


# ==============================================================================
# Helper Functions for Synthetic Data
# ==============================================================================


def generate_synthetic_velocity_data(
    model_class,
    true_pars: Dict[str, float],
    image_pars: ImagePars,
    snr: float,
    config: TestConfig,
) -> Tuple[jnp.ndarray, jnp.ndarray, float]:
    """
    Generate synthetic velocity data with noise.

    Parameters
    ----------
    model_class : type
        Velocity model class (e.g., CenteredVelocityModel).
    true_pars : dict
        True parameter values (using model's parameter names).
        Can contain extra parameters that will be filtered out (e.g. joint models).
    image_pars : ImagePars
        Image parameters defining the grid.
    snr : float
        Target signal-to-noise ratio.
    config : TestConfig
        Test configuration.

    Returns
    -------
    data_true : jnp.ndarray
        Noiseless synthetic data.
    data_noisy : jnp.ndarray
        Noisy synthetic data.
    variance : float
        Noise variance used.
    """

    model = model_class()

    # filter parameters to only include those needed by velocity model
    # this is relevant for joint models
    vel_pars = {k: v for k, v in true_pars.items() if k in model.PARAMETER_NAMES}

    theta_true = model.pars2theta(vel_pars)
    X, Y = build_map_grid_from_image_pars(image_pars, unit='arcsec', centered=True)
    data_true = model(theta_true, 'obs', X, Y)

    # Use synthetic module for noise generation
    synth = SyntheticVelocity(vel_pars, model_type='arctan', seed=config.seed)
    data_noisy = synth.generate(
        image_pars,
        snr=snr,
        seed=config.seed,
        include_poisson=config.include_poisson_noise,
    )
    variance = synth.variance
    data_true = synth.data_true  # Use synthetic's version for consistency

    return data_true, data_noisy, variance


def generate_synthetic_intensity_data(
    model_class,
    true_pars: Dict[str, float],
    image_pars: ImagePars,
    snr: float,
    config: TestConfig,
) -> Tuple[jnp.ndarray, jnp.ndarray, float]:
    """
    Generate synthetic intensity data with noise.

    Parameters
    ----------
    model_class : type
        Intensity model class (e.g., InclinedExponentialModel).
    true_pars : dict
        True parameter values (using model's parameter names).
        Can contain extra parameters that will be filtered out (e.g. joint models).
    image_pars : ImagePars
        Image parameters defining the grid.
    snr : float
        Target signal-to-noise ratio.
    config : TestConfig
        Test configuration.

    Returns
    -------
    data_true : jnp.ndarray
        Noiseless synthetic data.
    data_noisy : jnp.ndarray
        Noisy synthetic data.
    variance : float
        Noise variance used.
    """

    model = model_class()

    # filter parameters to only include those needed by intensity model
    # this is relevant for joint models
    int_pars = {k: v for k, v in true_pars.items() if k in model.PARAMETER_NAMES}

    theta_true = model.pars2theta(int_pars)
    X, Y = build_map_grid_from_image_pars(image_pars, unit='arcsec', centered=True)
    data_true = model(theta_true, 'obs', X, Y)

    # Use synthetic module for noise generation
    synth = SyntheticIntensity(int_pars, model_type='exponential', seed=config.seed)
    data_noisy = synth.generate(
        image_pars,
        snr=snr,
        seed=config.seed,
        include_poisson=config.include_poisson_noise,
        sersic_backend=config.sersic_backend,
    )
    variance = synth.variance
    data_true = synth.data_true

    return data_true, data_noisy, variance


# ==============================================================================
# Test: Centered Velocity Model (Base Case)
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_centered_velocity_base(snr, test_config, velocity_grids):
    """
    Test parameter recovery for CenteredVelocityModel (arctan rotation curve).

    Base case: no centroid offset, no shear, varying SNR levels.

    This is the simplest test case and serves as a sanity check that:
    - The forward model produces sensible velocity fields
    - The likelihood function is well-behaved
    - Parameters can be recovered in principle
    """

    X, Y = velocity_grids

    # Define true parameters using dict (robust to reordering)
    true_pars = {
        'cosi': 0.6,  # cos(inclination)
        'theta_int': 0.785,  # Position angle (radians, ~45 deg)
        'g1': 0.0,  # No shear
        'g2': 0.0,  # No shear
        'v0': 10.0,  # Systemic velocity (km/s)
        'vcirc': 200.0,  # Asymptotic circular velocity (km/s)
        'vel_rscale': 5.0,  # Scale radius (arcsec)
        'vel_x0': 0.0,  # No offset
        'vel_y0': 0.0,  # No offset
    }

    # Generate synthetic data
    model = CenteredVelocityModel()
    theta_true = model.pars2theta(true_pars)

    data_true, data_noisy, variance = generate_synthetic_velocity_data(
        CenteredVelocityModel,
        true_pars,
        test_config.image_pars_velocity,
        snr,
        test_config,
    )

    # Evaluate model at true parameters (for diagnostic plot)
    model_eval = model(theta_true, 'obs', X, Y)

    # Create diagnostic panels
    test_name = f"centered_velocity_base_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_noisy),
        data_true=np.asarray(data_true),
        model_eval=np.asarray(model_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='velocity',
        variance=variance,
        n_params=len(model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Create JIT-compiled likelihood
    log_like = create_jitted_likelihood_velocity(
        model, test_config.image_pars_velocity, variance, data_noisy
    )

    # Slice all parameters
    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        image_pars=test_config.image_pars_velocity,
    )

    # Plot likelihood slices and get recovery stats
    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'velocity'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Centered velocity (base)')


# ==============================================================================
# Test: Centered Velocity Model with Shear
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_centered_velocity_with_shear(snr, test_config, velocity_grids):
    """
    Test parameter recovery with non-zero shear.

    This test verifies g1 and g2 can be recovered along with kinematic parameters.
    """

    X, Y = velocity_grids

    # True parameters with significant shear
    true_pars = {
        'cosi': 0.6,
        'theta_int': 0.785,
        'g1': 0.05,  # Non-zero shear
        'g2': -0.03,  # Non-zero shear
        'v0': 10.0,
        'vcirc': 200.0,
        'vel_rscale': 5.0,
    }

    model = CenteredVelocityModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_velocity_data(
        CenteredVelocityModel,
        true_pars,
        test_config.image_pars_velocity,
        snr,
        test_config,
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"centered_velocity_with_shear_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_noisy),
        data_true=np.asarray(data_true),
        model_eval=np.asarray(model_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='velocity',
        variance=variance,
        n_params=len(model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_velocity(
        model, test_config.image_pars_velocity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        image_pars=test_config.image_pars_velocity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'velocity'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Centered velocity (w/ shear)')


# ==============================================================================
# Test: Offset Velocity Model
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_offset_velocity(snr, test_config, velocity_grids):
    """
    Test parameter recovery for OffsetVelocityModel.

    Includes centroid offsets (vel_x0, vel_y0) in addition to kinematic parameters.
    This tests our ability to recover spatial offsets along with velocities.
    """

    X, Y = velocity_grids

    # True parameters with centroid offset
    true_pars = {
        'cosi': 0.6,
        'theta_int': 0.785,
        'g1': 0.02,
        'g2': -0.01,
        'v0': 10.0,
        'vcirc': 200.0,
        'vel_rscale': 5.0,  # Scale radius (arcsec)
        'vel_x0': 1.5,  # Offset in x (arcsec)
        'vel_y0': -1.0,  # Offset in y (arcsec)
    }

    model = OffsetVelocityModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_velocity_data(
        OffsetVelocityModel,
        true_pars,
        test_config.image_pars_velocity,
        snr,
        test_config,
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"offset_velocity_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_noisy),
        data_true=np.asarray(data_true),
        model_eval=np.asarray(model_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='velocity',
        variance=variance,
        n_params=len(model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_velocity(
        model, test_config.image_pars_velocity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        image_pars=test_config.image_pars_velocity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'velocity'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Offset velocity')


# ==============================================================================
# Test: Inclined Exponential Intensity Model (Base Case)
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_inclined_exponential(snr, test_config, intensity_grids):
    """Test parameter recovery for InclinedExponentialModel."""

    X, Y = intensity_grids

    # True parameters
    true_pars = {
        'cosi': 0.7,  # Should affect ellipticity
        'theta_int': 0.785,
        'g1': 0.0,
        'g2': 0.0,
        'flux': 1.0,  # total flux
        'int_rscale': 3.0,  # Scale length (arcsec)
        'int_x0': 0.0,  # No offset (arcsec)
        'int_y0': 0.0,  # No offset (arcsec)
    }

    model = InclinedExponentialModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_intensity_data(
        InclinedExponentialModel,
        true_pars,
        test_config.image_pars_intensity,
        snr,
        test_config,
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"inclined_exponential_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_noisy),
        data_true=np.asarray(data_true),
        model_eval=np.asarray(model_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='intensity',
        variance=variance,
        n_params=len(model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_intensity(
        model, test_config.image_pars_intensity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        image_pars=test_config.image_pars_intensity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'intensity'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Inclined exponential (base)')


# ==============================================================================
# Test: Inclined Exponential with Shear
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_inclined_exponential_with_shear(snr, test_config, intensity_grids):
    """Test parameter recovery for InclinedExponentialModel with shear."""

    X, Y = intensity_grids

    # True parameters with non-zero shear
    true_pars = {
        'cosi': 0.7,
        'theta_int': 0.785,
        'g1': 0.03,  # Non-zero shear
        'g2': -0.02,  # Non-zero shear
        'flux': 1.0,
        'int_rscale': 3.0,
        'int_x0': 0.0,
        'int_y0': 0.0,
    }

    model = InclinedExponentialModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_intensity_data(
        InclinedExponentialModel,
        true_pars,
        test_config.image_pars_intensity,
        snr,
        test_config,
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"inclined_exponential_with_shear_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_noisy),
        data_true=np.asarray(data_true),
        model_eval=np.asarray(model_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='intensity',
        variance=variance,
        n_params=len(model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_intensity(
        model, test_config.image_pars_intensity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        image_pars=test_config.image_pars_intensity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'intensity'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Inclined exponential (w/ shear)')


# ==============================================================================
# Test: Joint Model (Base Case)
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_joint_base(snr, test_config, velocity_grids, intensity_grids):
    """
    Test parameter recovery for joint velocity + intensity model.

    Base case: no shear, centered galaxy. This tests the ability to
    simultaneously constrain kinematic and morphological parameters.
    """

    X_vel, Y_vel = velocity_grids
    X_int, Y_int = intensity_grids

    # Define true parameters for both models
    # Shared parameters: cosi, theta_int, g1, g2
    true_pars = {
        # Shared geometry
        'cosi': 0.6,
        'theta_int': 0.785,
        'g1': 0.0,  # No shear
        'g2': 0.0,
        # Velocity parameters
        'v0': 10.0,
        'vcirc': 200.0,
        'vel_rscale': 5.0,
        'vel_x0': 0.0,
        'vel_y0': 0.0,
        # Intensity parameters
        'flux': 1.0,
        'int_rscale': 3.0,
        'int_x0': 0.0,
        'int_y0': 0.0,
    }

    # Create joint model
    vel_model = OffsetVelocityModel()
    int_model = InclinedExponentialModel()
    joint_model = KLModel(
        vel_model, int_model, shared_pars={'cosi', 'theta_int', 'g1', 'g2'}
    )
    theta_true = joint_model.pars2theta(true_pars)

    # Generate synthetic data for both components
    data_vel_true, data_vel_noisy, variance_vel = generate_synthetic_velocity_data(
        OffsetVelocityModel,
        true_pars,
        test_config.image_pars_velocity,
        snr,
        test_config,
    )

    data_int_true, data_int_noisy, variance_int = generate_synthetic_intensity_data(
        InclinedExponentialModel,
        true_pars,
        test_config.image_pars_intensity,
        snr,
        test_config,
    )

    # Evaluate models at true parameters
    theta_vel_true = vel_model.pars2theta(true_pars)
    theta_int_true = int_model.pars2theta(true_pars)
    model_vel_eval = vel_model(theta_vel_true, 'obs', X_vel, Y_vel)
    model_int_eval = int_model(theta_int_true, 'obs', X_int, Y_int)

    # Diagnostic plots for both data types
    test_name = f"joint_base_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_vel_noisy),
        data_true=np.asarray(data_vel_true),
        model_eval=np.asarray(model_vel_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='velocity',
        variance=variance_vel,
        n_params=len(vel_model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    plot_data_comparison_panels(
        data_noisy=np.asarray(data_int_noisy),
        data_true=np.asarray(data_int_true),
        model_eval=np.asarray(model_int_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='intensity',
        variance=variance_int,
        n_params=len(int_model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Create joint likelihood
    log_like = create_jitted_likelihood_joint(
        joint_model,
        test_config.image_pars_velocity,
        test_config.image_pars_intensity,
        variance_vel,
        variance_int,
        data_vel_noisy,
        data_int_noisy,
    )

    # Slice all joint parameters
    # Note: for joint models, we can't easily determine which ImagePars to use
    # for bounds, so we pass None and let default behavior handle it
    slices = slice_all_parameters(
        log_like,
        joint_model,
        theta_true,
        test_config,
        image_pars=None,  # Will use default bounds
    )

    # Plot likelihood slices
    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'joint'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Joint model (base)')


# ==============================================================================
# Test: Joint Model with Shear
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 50, 10])
def test_recover_joint_with_shear(snr, test_config, velocity_grids, intensity_grids):
    """
    Test parameter recovery for joint model with non-zero shear.

    This is the most comprehensive test, combining kinematic and morphological
    information to constrain shear along with all other parameters.
    """

    X_vel, Y_vel = velocity_grids
    X_int, Y_int = intensity_grids

    # Define true parameters with shear
    true_pars = {
        # Shared geometry (including shear)
        'cosi': 0.6,
        'theta_int': 0.785,
        'g1': 0.03,  # Non-zero shear
        'g2': -0.02,
        # Velocity parameters
        'v0': 10.0,
        'vcirc': 200.0,
        'vel_rscale': 5.0,
        'vel_x0': 1.0,  # Slight offset
        'vel_y0': -0.5,
        # Intensity parameters
        'flux': 1.0,
        'int_rscale': 3.0,
        'int_x0': 1.0,  # Same offset (aligned)
        'int_y0': -0.5,
    }

    # Create joint model
    vel_model = OffsetVelocityModel()
    int_model = InclinedExponentialModel()
    joint_model = KLModel(
        vel_model, int_model, shared_pars={'cosi', 'theta_int', 'g1', 'g2'}
    )
    theta_true = joint_model.pars2theta(true_pars)

    # Generate synthetic data
    data_vel_true, data_vel_noisy, variance_vel = generate_synthetic_velocity_data(
        OffsetVelocityModel,
        true_pars,
        test_config.image_pars_velocity,
        snr,
        test_config,
    )

    data_int_true, data_int_noisy, variance_int = generate_synthetic_intensity_data(
        InclinedExponentialModel,
        true_pars,
        test_config.image_pars_intensity,
        snr,
        test_config,
    )

    # Evaluate models at true parameters
    theta_vel_true = vel_model.pars2theta(true_pars)
    theta_int_true = int_model.pars2theta(true_pars)
    model_vel_eval = vel_model(theta_vel_true, 'obs', X_vel, Y_vel)
    model_int_eval = int_model(theta_int_true, 'obs', X_int, Y_int)

    # Diagnostic plots
    test_name = f"joint_with_shear_snr{snr}"
    plot_data_comparison_panels(
        data_noisy=np.asarray(data_vel_noisy),
        data_true=np.asarray(data_vel_true),
        model_eval=np.asarray(model_vel_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='velocity',
        variance=variance_vel,
        n_params=len(vel_model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    plot_data_comparison_panels(
        data_noisy=np.asarray(data_int_noisy),
        data_true=np.asarray(data_int_true),
        model_eval=np.asarray(model_int_eval),
        test_name=test_name,
        output_dir=test_config.output_dir / test_name,
        data_type='intensity',
        variance=variance_int,
        n_params=len(int_model.PARAMETER_NAMES),
        enable_plots=test_config.enable_plots,
    )

    # Create joint likelihood
    log_like = create_jitted_likelihood_joint(
        joint_model,
        test_config.image_pars_velocity,
        test_config.image_pars_intensity,
        variance_vel,
        variance_int,
        data_vel_noisy,
        data_int_noisy,
    )

    # Slice all joint parameters
    slices = slice_all_parameters(
        log_like,
        joint_model,
        theta_true,
        test_config,
        image_pars=None,
    )

    # Plot likelihood slices
    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, 'joint'
    )

    assert_parameter_recovery(recovery_stats, snr, 'Joint model (w/ shear)')


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
