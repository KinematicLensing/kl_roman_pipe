"""
Parameter recovery tests using likelihood slicing.

Tests validate that:
1. Forward models are implemented correctly
2. Likelihood functions are well-behaved
3. True parameters can be recovered in principle

Each test generates synthetic data with known parameters, then slices the
log-likelihood along each parameter dimension to verify it peaks near the
true value.

Diagnostic plots are generated by default showing:
- 2x3 panel plots: [noisy|true|noisy-true] and [noisy|model|noisy-model]
- Likelihood slices for each parameter with true value and recovered peak
"""

import pytest
import jax.numpy as jnp
import numpy as np
from typing import Dict, Tuple

from kl_pipe.velocity import CenteredVelocityModel, OffsetVelocityModel
from kl_pipe.intensity import InclinedExponentialModel
from kl_pipe.model import KLModel
from kl_pipe.synthetic import SyntheticVelocity, SyntheticIntensity
from kl_pipe.likelihood import (
    create_jitted_likelihood_velocity,
    create_jitted_likelihood_intensity,
    create_jitted_likelihood_joint,
)
from kl_pipe.utils import build_map_grid_from_image_pars, get_test_dir

# Import our shared test utilities
from test_utils import (
    TestConfig,
    slice_all_parameters,
    plot_data_comparison_panels,
    plot_likelihood_slices,
)


# ==============================================================================
# Pytest Fixtures
# ==============================================================================


@pytest.fixture(scope="module")
def test_config():
    """
    Test configuration fixture.

    This replaces global variables and makes configuration explicit.
    To modify behavior, edit TestConfig in test_utils.py.
    """

    out_dir = get_test_dir() / "out" / "likelihood_slices"
    config = TestConfig(out_dir, include_poisson_noise=False)
    config.output_dir.mkdir(parents=True, exist_ok=True)

    return config


@pytest.fixture
def velocity_grids(test_config):
    """Pre-computed coordinate grids for velocity tests (32x32)."""
    X, Y = build_map_grid_from_image_pars(
        test_config.image_pars_velocity, unit='arcsec', centered=True
    )
    return X, Y


@pytest.fixture
def intensity_grids(test_config):
    """Pre-computed coordinate grids for intensity tests (64x64)."""
    X, Y = build_map_grid_from_image_pars(
        test_config.image_pars_intensity, unit='arcsec', centered=True
    )
    return X, Y


# ==============================================================================
# Helper Functions for Synthetic Data
# ==============================================================================


def generate_synthetic_velocity_data(
    model_class,
    true_pars: Dict[str, float],
    X: jnp.ndarray,
    Y: jnp.ndarray,
    snr: float,
    config: TestConfig,
) -> Tuple[jnp.ndarray, jnp.ndarray, float]:
    """
    Generate synthetic velocity data with noise.

    Parameters
    ----------
    model_class : type
        Velocity model class (e.g., CenteredVelocityModel).
    true_pars : dict
        True parameter values (using model's parameter names).
    X, Y : jnp.ndarray
        Coordinate grids.
    snr : float
        Target signal-to-noise ratio.
    config : TestConfig
        Test configuration.

    Returns
    -------
    data_true : jnp.ndarray
        Noiseless synthetic data.
    data_noisy : jnp.ndarray
        Noisy synthetic data.
    variance : float
        Noise variance used.
    """

    # Generate true model
    model = model_class()
    theta_true = model.pars2theta(true_pars)
    data_true = model(theta_true, 'obs', X, Y)

    # Use synthetic module for noise generation
    # Note: synthetic.py now uses same parameter names after update
    synth = SyntheticVelocity(true_pars, model_type='arctan', seed=config.seed)
    data_noisy = synth.generate(
        X, Y, snr=snr, seed=config.seed, include_poisson=config.include_poisson_noise
    )
    variance = synth.variance
    data_true = synth.data_true  # Use synthetic's version for consistency

    return data_true, data_noisy, variance


def generate_synthetic_intensity_data(
    model_class,
    true_pars: Dict[str, float],
    X: jnp.ndarray,
    Y: jnp.ndarray,
    snr: float,
    config: TestConfig,
) -> Tuple[jnp.ndarray, jnp.ndarray, float]:
    """
    Generate synthetic intensity data with noise.

    Parameters
    ----------
    model_class : type
        Intensity model class (e.g., InclinedExponentialModel).
    true_pars : dict
        True parameter values (using model's parameter names).
    X, Y : jnp.ndarray
        Coordinate grids.
    snr : float
        Target signal-to-noise ratio.
    config : TestConfig
        Test configuration.

    Returns
    -------
    data_true : jnp.ndarray
        Noiseless synthetic data.
    data_noisy : jnp.ndarray
        Noisy synthetic data.
    variance : float
        Noise variance used.
    """

    # Generate true model
    model = model_class()
    theta_true = model.pars2theta(true_pars)
    data_true = model(theta_true, 'obs', X, Y)

    # Use synthetic module for noise generation
    # Note: synthetic.py now uses same parameter names after update
    synth = SyntheticIntensity(true_pars, model_type='exponential', seed=config.seed)
    data_noisy = synth.generate(
        X, Y, snr=snr, seed=config.seed, include_poisson=config.include_poisson_noise
    )
    variance = synth.variance
    data_true = synth.data_true

    return data_true, data_noisy, variance


# ==============================================================================
# Test: Centered Velocity Model (Base Case)
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 500, 100])
def test_recover_centered_velocity_base(snr, test_config, velocity_grids):
    """
    Test parameter recovery for CenteredVelocityModel (arctan rotation curve).

    Base case: no centroid offset, no shear, varying SNR levels.

    This is the simplest test case and serves as a sanity check that:
    - The forward model produces sensible velocity fields
    - The likelihood function is well-behaved
    - Parameters can be recovered in principle
    """

    X, Y = velocity_grids
    tolerance = test_config.get_tolerance(snr, 'velocity')

    # Define true parameters using dict (robust to reordering)
    true_pars = {
        'cosi': 0.6,  # cos(inclination)
        'theta_int': 0.785,  # Position angle (radians, ~45 deg)
        'g1': 0.0,  # No shear
        'g2': 0.0,  # No shear
        'v0': 10.0,  # Systemic velocity (km/s)
        'vcirc': 200.0,  # Asymptotic circular velocity (km/s)
        'vel_rscale': 5.0,  # Scale radius (arcsec)
        'vel_x0': 0.0,  # No offset
        'vel_y0': 0.0,  # No offset
    }

    # Generate synthetic data
    model = CenteredVelocityModel()
    theta_true = model.pars2theta(true_pars)

    data_true, data_noisy, variance = generate_synthetic_velocity_data(
        CenteredVelocityModel, true_pars, X, Y, snr, test_config
    )

    # Evaluate model at true parameters (for diagnostic plot)
    model_eval = model(theta_true, 'obs', X, Y)

    # Create diagnostic panels
    test_name = f"centered_velocity_base_snr{snr}"
    plot_data_comparison_panels(
        data_noisy, data_true, model_eval, test_name, test_config, data_type='velocity'
    )

    # Create JIT-compiled likelihood
    log_like = create_jitted_likelihood_velocity(
        model, test_config.image_pars_velocity, variance, data_noisy
    )

    # Slice all parameters
    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        n_points=50,
        image_pars=test_config.image_pars_velocity,
    )

    # Plot likelihood slices and get recovery stats
    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, tolerance
    )

    # Assert all parameters recovered within tolerance
    failed_params = []
    for param_name, stats in recovery_stats.items():
        if not stats['passed']:
            failed_params.append(
                f"{param_name}: {stats['pct_error']*100:.2f}% error "
                f"(recovered {stats['recovered']:.4f}, true {stats['true']:.4f})"
            )

    if failed_params:
        msg = f"Parameter recovery failed for SNR={snr}:\n" + "\n".join(failed_params)
        pytest.fail(msg)


# ==============================================================================
# Test: Centered Velocity Model with Shear
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 500, 100])
def test_recover_centered_velocity_with_shear(snr, test_config, velocity_grids):
    """
    Test parameter recovery with non-zero shear.

    This test verifies g1 and g2 can be recovered along with kinematic parameters.
    """

    X, Y = velocity_grids
    tolerance = test_config.get_tolerance(snr, 'velocity')

    # True parameters with significant shear
    true_pars = {
        'cosi': 0.6,
        'theta_int': 0.785,
        'g1': 0.05,  # Non-zero shear
        'g2': -0.03,  # Non-zero shear
        'v0': 10.0,
        'vcirc': 200.0,
        'vel_rscale': 5.0,
    }

    model = CenteredVelocityModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_velocity_data(
        CenteredVelocityModel, true_pars, X, Y, snr, test_config
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"centered_velocity_with_shear_snr{snr}"
    plot_data_comparison_panels(
        data_noisy, data_true, model_eval, test_name, test_config, data_type='velocity'
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_velocity(
        model, test_config.image_pars_velocity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        n_points=50,
        image_pars=test_config.image_pars_velocity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, tolerance
    )

    # Assert recovery
    failed_params = []
    for param_name, stats in recovery_stats.items():
        if not stats['passed']:
            failed_params.append(
                f"{param_name}: {stats['pct_error']*100:.2f}% error "
                f"(recovered {stats['recovered']:.4f}, true {stats['true']:.4f})"
            )

    if failed_params:
        msg = f"Parameter recovery with shear failed for SNR={snr}:\n" + "\n".join(
            failed_params
        )
        pytest.fail(msg)


# ==============================================================================
# Test: Offset Velocity Model
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 500, 100])
def test_recover_offset_velocity(snr, test_config, velocity_grids):
    """
    Test parameter recovery for OffsetVelocityModel.

    Includes centroid offsets (vel_x0, vel_y0) in addition to kinematic parameters.
    This tests our ability to recover spatial offsets along with velocities.
    """

    X, Y = velocity_grids
    tolerance = test_config.get_tolerance(snr, 'velocity')

    # True parameters with centroid offset
    true_pars = {
        'cosi': 0.6,
        'theta_int': 0.785,
        'g1': 0.02,
        'g2': -0.01,
        'v0': 10.0,
        'vcirc': 200.0,
        'vel_rscale': 5.0,  # Scale radius (arcsec)
        'vel_x0': 1.5,  # Offset in x (arcsec)
        'vel_y0': -1.0,  # Offset in y (arcsec)
    }

    model = OffsetVelocityModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_velocity_data(
        OffsetVelocityModel, true_pars, X, Y, snr, test_config
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"offset_velocity_snr{snr}"
    plot_data_comparison_panels(
        data_noisy, data_true, model_eval, test_name, test_config, data_type='velocity'
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_velocity(
        model, test_config.image_pars_velocity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        n_points=50,
        image_pars=test_config.image_pars_velocity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, tolerance
    )

    # Assert recovery
    failed_params = []
    for param_name, stats in recovery_stats.items():
        if not stats['passed']:
            failed_params.append(
                f"{param_name}: {stats['pct_error']*100:.2f}% error "
                f"(recovered {stats['recovered']:.4f}, true {stats['true']:.4f})"
            )

    if failed_params:
        msg = f"Offset velocity recovery failed for SNR={snr}:\n" + "\n".join(
            failed_params
        )
        pytest.fail(msg)


# ==============================================================================
# Test: Inclined Exponential Intensity Model
# ==============================================================================


@pytest.mark.parametrize("snr", [1000, 500, 100])
def test_recover_inclined_exponential(snr, test_config, intensity_grids):
    """
    Test parameter recovery for InclinedExponentialModel.

    NOTE: This test is expected to fail initially because the inclination
    is not yet properly implemented in the model. The test should reveal
    that cosi cannot be recovered, indicating the bug.

    Once the model is fixed to properly apply inclination, this test should pass.
    """

    X, Y = intensity_grids
    tolerance = test_config.get_tolerance(snr, 'intensity')

    # True parameters
    true_pars = {
        'cosi': 0.7,  # Should affect ellipticity
        'theta_int': 0.785,
        'g1': 0.0,
        'g2': 0.0,
        'I0': 1.0,  # Central intensity
        'int_rscale': 3.0,  # Scale length (arcsec)
        'int_x0': 0.0,  # No offset (arcsec)
        'int_y0': 0.0,  # No offset (arcsec)
    }

    model = InclinedExponentialModel()
    theta_true = model.pars2theta(true_pars)

    # Generate synthetic data
    data_true, data_noisy, variance = generate_synthetic_intensity_data(
        InclinedExponentialModel, true_pars, X, Y, snr, test_config
    )

    model_eval = model(theta_true, 'obs', X, Y)

    # Diagnostic plots
    test_name = f"inclined_exponential_snr{snr}"
    plot_data_comparison_panels(
        data_noisy, data_true, model_eval, test_name, test_config, data_type='intensity'
    )

    # Likelihood slicing
    log_like = create_jitted_likelihood_intensity(
        model, test_config.image_pars_intensity, variance, data_noisy
    )

    slices = slice_all_parameters(
        log_like,
        model,
        theta_true,
        test_config,
        n_points=50,
        image_pars=test_config.image_pars_intensity,
    )

    recovery_stats = plot_likelihood_slices(
        slices, true_pars, test_name, test_config, snr, tolerance
    )

    # Assert recovery
    # NOTE: We expect cosi to fail if inclination is not implemented
    failed_params = []
    for param_name, stats in recovery_stats.items():
        if not stats['passed']:
            failed_params.append(
                f"{param_name}: {stats['pct_error']*100:.2f}% error "
                f"(recovered {stats['recovered']:.4f}, true {stats['true']:.4f})"
            )

    if failed_params:
        msg = f"Inclined exponential recovery failed for SNR={snr}:\n" + "\n".join(
            failed_params
        )
        msg += "\n\nNOTE: If only 'cosi' failed, this likely indicates the inclination "
        msg += "is not yet properly implemented in InclinedExponentialModel."
        pytest.fail(msg)


if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
